{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image, ImageEnhance\n",
    "image_path1 = r\"H:\\LUMS\\Dr-Murtaza-Taj\\Camera-Calibration\\brandenburg_gate\\dense\\images\\00581890_3574867299.jpg\"\n",
    "image_path2 = r\"H:\\LUMS\\Dr-Murtaza-Taj\\Camera-Calibration\\brandenburg_gate\\dense\\images\\01738801_5114523193.jpg\"\n",
    "target_size = (150, 150)\n",
    "target_mean = 127.5\n",
    "target_std = 80\n",
    "processed_images = []\n",
    "for image_path in [image_path1, image_path2]:\n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"Error: Image not found at: {image_path}\")\n",
    "        continue\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "       print(f\"Error: Failed to load image at: {image_path}\")\n",
    "       continue\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    current_mean = np.mean(img_gray)\n",
    "    current_std = np.std(img_gray)  \n",
    "    if current_std!=0:\n",
    "        scale_factor = target_std / current_std\n",
    "        brightness_offset = target_mean - current_mean * scale_factor\n",
    "        img_adjusted = cv2.convertScaleAbs(img, alpha=scale_factor, beta=brightness_offset)\n",
    "    else:\n",
    "        img_adjusted = img\n",
    "    pil_img = Image.fromarray(cv2.cvtColor(img_adjusted, cv2.COLOR_BGR2RGB))\n",
    "    resized_img = pil_img.resize(target_size, Image.Resampling.LANCZOS)\n",
    "    processed_images.append(resized_img)\n",
    "if len(processed_images) == 2:\n",
    "    processed_images[0].show(title=\"Processed Image 1\")\n",
    "    processed_images[1].show(title=\"Processed Image 2\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera pose for image (ID = 1363):\n",
      "  RT matrix:\n",
      "[[ 0.84066541 -0.09035049 -0.53396484  3.4599676 ]\n",
      " [ 0.10270195  0.99469017 -0.00661611 -0.20256423]\n",
      " [ 0.53172735 -0.0492773   0.8454808  -0.57750759]]\n",
      "  Intrinsic matrix:\n",
      "[[1.24885779e+03 0.00000000e+00 5.16500000e+02]\n",
      " [0.00000000e+00 1.24885779e+03 3.42500000e+02]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00]]\n",
      "  Rotation constraints valid: True\n",
      "  Projection constraints valid: True\n",
      "Camera pose for image (ID = 697):\n",
      "  RT matrix:\n",
      "[[ 8.95122025e-01 -5.96068065e-02 -4.41818503e-01  2.84904576e+00]\n",
      " [ 6.77420807e-02  9.97699366e-01  2.64306598e-03  7.96587957e-02]\n",
      " [ 4.40644495e-01 -3.22955713e-02  8.97100566e-01  5.58065177e-01]]\n",
      "  Intrinsic matrix:\n",
      "[[834.0489502   0.        517.       ]\n",
      " [  0.        834.0489502 385.5      ]\n",
      " [  0.          0.          1.       ]]\n",
      "  Rotation constraints valid: True\n",
      "  Projection constraints valid: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "file_path_cameras = r\"brandenburg_gate\\neuralsfm\\cameras.txt\"\n",
    "k_matrices = []\n",
    "with open(file_path_cameras, 'r') as file:\n",
    "    lines = file.readlines()\n",
    "    relevant_lines = lines[3:1366]\n",
    "    for line in relevant_lines:\n",
    "        parts = line.strip().split()\n",
    "        camera_id = int(parts[0])\n",
    "        model = parts[1].strip()\n",
    "        width = int(parts[2])\n",
    "        height = int(parts[3])\n",
    "        params = list(map(float, parts[4:]))\n",
    "        if len(params) < 4:\n",
    "            continue\n",
    "        \n",
    "        f_x, f_y, c_x, c_y = params[:4]\n",
    "        K = np.array([\n",
    "            [f_x, 0, c_x],\n",
    "            [0, f_y, c_y],\n",
    "            [0, 0, 1]\n",
    "        ])\n",
    "        k_matrices.append((camera_id, K))\n",
    "intrinsics  = []        \n",
    "intrinsics.append(k_matrices[3][1])\n",
    "intrinsics.append(k_matrices[17][1])\n",
    "\n",
    "def quaternion_to_rotation_matrix(qw, qx, qy, qz):\n",
    "    R = np.array([\n",
    "    [1 - 2*(qy**2 + qz**2), 2*(qx*qy - qz*qw), 2*(qx*qz + qy*qw)],\n",
    "    [2*(qx*qy + qz*qw), 1 - 2*(qx**2 + qz**2), 2*(qy*qz - qx*qw)],\n",
    "    [2*(qx*qz - qy*qw), 2*(qy*qz + qx*qw), 1 - 2*(qx**2 + qy**2)]\n",
    "    ])\n",
    "    return R\n",
    "\n",
    "file_path_images = r\"brandenburg_gate\\neuralsfm\\images.txt\"\n",
    "camera_poses = []\n",
    "with open(file_path_images, 'r') as file:\n",
    "    lines = file.readlines()\n",
    "    for i in range(4, len(lines), 2): \n",
    "        line1 = lines[i].strip()\n",
    "        line2 = lines[i+1].strip() if i + 1 < len(lines) else \"\"\n",
    "        \n",
    "        if line1.startswith('#') or not line1 or line2.startswith('#') or not line2:\n",
    "            continue\n",
    "        parts1 = line1.split()\n",
    "        parts2 = line2.split()\n",
    "        image_id = int(parts1[0]) \n",
    "        qw, qx, qy, qz = map(float, parts1[1:5]) \n",
    "        tx, ty, tz = map(float, parts1[5:8])  \n",
    "        R = quaternion_to_rotation_matrix(qw, qx, qy, qz)  \n",
    "        t = np.array([tx, ty, tz]).reshape(3,1) \n",
    "        camera_poses.append((image_id, R, t)) \n",
    "\n",
    "combined_poses = {}\n",
    "indices = [3, 17]\n",
    "for i, (image_id, R, t) in enumerate(camera_poses):\n",
    "    if i in indices:\n",
    "        RT = np.concatenate((R, t), axis=1)\n",
    "        combined_poses[image_id] = RT\n",
    "\n",
    "# --- Constraint Verification Functions ---\n",
    "def verify_rotation_constraints(R, tolerance=1e-6):\n",
    "    r1 = R[0, :]\n",
    "    r2 = R[1, :]\n",
    "    r3 = R[2, :]\n",
    "    if (abs(np.dot(r1, r2)) > tolerance or\n",
    "        abs(np.dot(r1, r3)) > tolerance or\n",
    "        abs(np.dot(r2, r3)) > tolerance):\n",
    "        return False\n",
    "    identity = np.eye(3)\n",
    "    if not np.all(np.abs(np.dot(R, R.T) - identity) < tolerance):\n",
    "        return False\n",
    "    if abs(np.linalg.det(R) - 1) > tolerance:\n",
    "       return False\n",
    "    return True\n",
    "\n",
    "def verify_projection_constraints(P, tolerance=1e-6):\n",
    "  vx = P[:3, 0] / P[2,0]\n",
    "  vy = P[:3, 1] / P[2,1]\n",
    "  vz = P[:3, 2] / P[2,2]\n",
    "  wc = P[:3, 3] / P[2,3]\n",
    "  if (abs(vx[0]) < tolerance or abs(vx[1]) < tolerance or\n",
    "      abs(vy[0]) < tolerance or abs(vy[1]) < tolerance or\n",
    "          abs(vz[0]) < tolerance or abs(vz[1]) < tolerance):\n",
    "      return False\n",
    "  return True\n",
    "\n",
    "for i, (image_id, RT) in enumerate(combined_poses.items()):\n",
    "    print(f\"Camera pose for image (ID = {image_id}):\")\n",
    "    print(f\"  RT matrix:\\n{RT}\")\n",
    "    if i < len(intrinsics):\n",
    "        K = intrinsics[i]\n",
    "        print(f\"  Intrinsic matrix:\\n{K}\")\n",
    "        R = RT[:,:3]\n",
    "        t = RT[:,3:]\n",
    "        P = np.dot(K, np.concatenate((R, t), axis=1))\n",
    "        rotation_valid = verify_rotation_constraints(R)\n",
    "        projection_valid = verify_projection_constraints(P)\n",
    "        print(f\"  Rotation constraints valid: {rotation_valid}\")\n",
    "        print(f\"  Projection constraints valid: {projection_valid}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "[[1.24886000e+03 0.00000000e+00 5.17000000e+02]\n",
       " [0.00000000e+00 1.24886000e+03 3.43000000e+02]\n",
       " [0.00000000e+00 0.00000000e+00 1.00000000e+00]]\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import base64\n",
    "import google.generativeai as genai\n",
    "from IPython.display import Markdown\n",
    "\n",
    "model = genai.GenerativeModel(model_name=\"gemini-2.0-flash-exp\")\n",
    "\n",
    "image_path_1 = r\"H:\\LUMS\\Dr-Murtaza-Taj\\Camera-Calibration\\brandenburg_gate\\dense\\images\\00581890_3574867299.jpg\"\n",
    "image_path_2 = r\"H:\\LUMS\\Dr-Murtaza-Taj\\Camera-Calibration\\brandenburg_gate\\dense\\images\\01738801_5114523193.jpg\"\n",
    "\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as img_file:\n",
    "        return base64.b64encode(img_file.read()).decode(\"utf-8\")\n",
    "\n",
    "sample_file_1 = {\n",
    "    \"mime_type\": \"image/jpeg\",\n",
    "    \"data\": encode_image(image_path_1)\n",
    "}\n",
    "\n",
    "sample_file_2 = {\n",
    "    \"mime_type\": \"image/jpeg\",\n",
    "    \"data\": encode_image(image_path_2)\n",
    "}\n",
    "\n",
    "prompt = \"The intrinsic matrix for Image 1 is given as:\\n\\n\" \\\n",
    "         \"[[1.24885779e+03 0.00000000e+00 5.16500000e+02]\\n\" \\\n",
    "         \" [0.00000000e+00 1.24885779e+03 3.42500000e+02]\\n\" \\\n",
    "         \" [0.00000000e+00 0.00000000e+00 1.00000000e+00]]\\n\\n\" \\\n",
    "         \"Given this, the image 2 is similar to image 1. Try to predict the intrinsic matrix for Image 2 in the same format. Do not repeat the exact first. :\\n\\n\" \\\n",
    "         \"Intrinsic Matrix (Image 2):\\n[[f_x, 0, c_x], [0, f_y, c_y], [0, 0, 1]]\\n\" \\\n",
    "         \"Do not include additional explanations.\"\n",
    "\n",
    "response = model.generate_content([sample_file_1, sample_file_2, prompt])\n",
    "\n",
    "Markdown(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "[[900.0, 0.0, 550.0], [0.0, 900.0, 370.0], [0.0, 0.0, 1.0]]"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import base64\n",
    "import google.generativeai as genai\n",
    "from IPython.display import Markdown\n",
    "\n",
    "model = genai.GenerativeModel(model_name=\"gemini-2.0-flash-exp\")\n",
    "\n",
    "image_path_1 = r\"brandenburg_gate\\dense\\images\\00581890_3574867299.jpg\"\n",
    "image_path_2 = r\"brandenburg_gate\\dense\\images\\01738801_5114523193.jpg\"\n",
    "\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as img_file:\n",
    "        return base64.b64encode(img_file.read()).decode(\"utf-8\")\n",
    "\n",
    "sample_file_1 = {\n",
    "    \"mime_type\": \"image/jpeg\",\n",
    "    \"data\": encode_image(image_path_1)\n",
    "}\n",
    "\n",
    "sample_file_2 = {\n",
    "    \"mime_type\": \"image/jpeg\",\n",
    "    \"data\": encode_image(image_path_2)\n",
    "}\n",
    "\n",
    "prompt = \"The intrinsic matrix for Image 1 is given as:\\n\\n\" \\\n",
    "         \"[[1.24885779e+03 0.00000000e+00 5.16500000e+02]\\n\" \\\n",
    "         \" [0.00000000e+00 1.24885779e+03 3.42500000e+02]\\n\" \\\n",
    "         \" [0.00000000e+00 0.00000000e+00 1.00000000e+00]]\\n\\n\" \\\n",
    "         \"Given this, the image 2 is similar to image 1. Try to predict the intrinsic matrix for Image 2 in the same format. fx fy values for image 2 are in range 700 to 1000. Do not average the range come with some apporoximation using the image :\\n\\n\" \\\n",
    "         \"Intrinsic Matrix (Image 2):\\n[[f_x, 0, c_x], [0, f_y, c_y], [0, 0, 1]]\\n\" \\\n",
    "         \"Do not include additional explanations.\"\n",
    "\n",
    "response = model.generate_content([sample_file_1, sample_file_2, prompt])\n",
    "\n",
    "Markdown(response.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>With Pre-Processing</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "[[1.24885779e+03, 0.00000000e+00, 5.16500000e+02], [0.00000000e+00, 1.24885779e+03, 3.42500000e+02], [0.00000000e+00, 0.00000000e+00, 1.00000000e+00]]\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import base64\n",
    "import cv2\n",
    "import google.generativeai as genai\n",
    "from IPython.display import Markdown\n",
    "\n",
    "model = genai.GenerativeModel(model_name=\"gemini-2.0-flash-exp\")\n",
    "\n",
    "image_path_1 = r\"brandenburg_gate\\dense\\images\\00581890_3574867299.jpg\"\n",
    "image_path_2 = r\"brandenburg_gate\\dense\\images\\01738801_5114523193.jpg\"\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    resized_image = cv2.resize(gray_image, (150, 150))\n",
    "    _, encoded_image = cv2.imencode('.jpg', resized_image)\n",
    "    return base64.b64encode(encoded_image).decode(\"utf-8\")\n",
    "\n",
    "sample_file_1 = {\n",
    "    \"mime_type\": \"image/jpeg\",\n",
    "    \"data\": preprocess_image(image_path_1)\n",
    "}\n",
    "\n",
    "sample_file_2 = {\n",
    "    \"mime_type\": \"image/jpeg\",\n",
    "    \"data\": preprocess_image(image_path_2)\n",
    "}\n",
    "\n",
    "prompt = \"The intrinsic matrix for Image 1 is given as:\\n\\n\" \\\n",
    "         \"[[1.24885779e+03 0.00000000e+00 5.16500000e+02]\\n\" \\\n",
    "         \" [0.00000000e+00 1.24885779e+03 3.42500000e+02]\\n\" \\\n",
    "         \" [0.00000000e+00 0.00000000e+00 1.00000000e+00]]\\n\\n\" \\\n",
    "         \"Given this, the image 2 is similar to image 1. Try to predict the intrinsic matrix for Image 2 in the same format. fx fy values for image 2 are in range 700 to 1000. Do not average the range, come with some approximation using the image:\\n\\n\" \\\n",
    "         \"Intrinsic Matrix (Image 2):\\n[[f_x, 0, c_x], [0, f_y, c_y], [0, 0, 1]]\\n\" \\\n",
    "         \"Do not include additional explanations.\"\n",
    "\n",
    "response = model.generate_content([sample_file_1, sample_file_2, prompt])\n",
    "\n",
    "Markdown(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "[[900, 0, 516], [0, 900, 342], [0, 0, 1]]\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import base64\n",
    "import cv2\n",
    "import google.generativeai as genai\n",
    "from IPython.display import Markdown\n",
    "\n",
    "model = genai.GenerativeModel(model_name=\"gemini-2.0-flash-exp\")\n",
    "\n",
    "image_path_1 = r\"brandenburg_gate\\dense\\images\\00581890_3574867299.jpg\"\n",
    "image_path_2 = r\"brandenburg_gate\\dense\\images\\01738801_5114523193.jpg\"\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    resized_image = cv2.resize(gray_image, (150, 150))\n",
    "    _, encoded_image = cv2.imencode('.jpg', resized_image)\n",
    "    return base64.b64encode(encoded_image).decode(\"utf-8\")\n",
    "\n",
    "sample_file_1 = {\n",
    "    \"mime_type\": \"image/jpeg\",\n",
    "    \"data\": preprocess_image(image_path_1)\n",
    "}\n",
    "\n",
    "sample_file_2 = {\n",
    "    \"mime_type\": \"image/jpeg\",\n",
    "    \"data\": preprocess_image(image_path_2)\n",
    "}\n",
    "\n",
    "prompt = \"\"\"The intrinsic matrix for Image 1 is given as:\n",
    "\n",
    "[[1.24885779e+03 0.00000000e+00 5.16500000e+02]\n",
    " [0.00000000e+00 1.24885779e+03 3.42500000e+02]\n",
    " [0.00000000e+00 0.00000000e+00 1.00000000e+00]]\n",
    "\n",
    "Image 2 is captured under similar conditions to Image 1. The scene is similar, and both images use the same camera type with a focal length in the range of 700 to 1000. The camera positions may vary slightly. Based on these factors, predict the intrinsic matrix for Image 2.\n",
    "\n",
    "Intrinsic Matrix (Image 2):\n",
    "[[f_x, 0, c_x], [0, f_y, c_y], [0, 0, 1]]\n",
    "Do not include additional explanations.\"\"\"\n",
    "\n",
    "response = model.generate_content([sample_file_1, sample_file_2, prompt])\n",
    "\n",
    "Markdown(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```\n",
       "[[800.0, 0.0, 516.5], [0.0, 800.0, 342.5], [0.0, 0.0, 1.0]]\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import base64\n",
    "import cv2\n",
    "import google.generativeai as genai\n",
    "from IPython.display import Markdown\n",
    "\n",
    "model = genai.GenerativeModel(model_name=\"gemini-2.0-flash-exp\")\n",
    "\n",
    "image_path_1 = r\"brandenburg_gate\\dense\\images\\00581890_3574867299.jpg\"\n",
    "image_path_2 = r\"brandenburg_gate\\dense\\images\\01738801_5114523193.jpg\"\n",
    "\n",
    "def preprocess_image_with_features_and_matches(image_path_1, image_path_2):\n",
    "    image_1 = cv2.imread(image_path_1)\n",
    "    image_2 = cv2.imread(image_path_2)\n",
    "    gray_image_1 = cv2.cvtColor(image_1, cv2.COLOR_BGR2GRAY)\n",
    "    gray_image_2 = cv2.cvtColor(image_2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    orb = cv2.ORB_create()\n",
    "    keypoints_1, descriptors_1 = orb.detectAndCompute(gray_image_1, None)\n",
    "    keypoints_2, descriptors_2 = orb.detectAndCompute(gray_image_2, None)\n",
    "\n",
    "    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "    matches = bf.match(descriptors_1, descriptors_2)\n",
    "    matches = sorted(matches, key = lambda x:x.distance)\n",
    "\n",
    "    img_with_matches = cv2.drawMatches(image_1, keypoints_1, image_2, keypoints_2, matches[:30], None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "    \n",
    "    _, encoded_image = cv2.imencode('.jpg', img_with_matches)\n",
    "    return base64.b64encode(encoded_image).decode(\"utf-8\")\n",
    "\n",
    "sample_file_1 = {\n",
    "    \"mime_type\": \"image/jpeg\",\n",
    "    \"data\": preprocess_image_with_features_and_matches(image_path_1, image_path_2)\n",
    "}\n",
    "\n",
    "sample_file_2 = {\n",
    "    \"mime_type\": \"image/jpeg\",\n",
    "    \"data\": preprocess_image_with_features_and_matches(image_path_1, image_path_2)\n",
    "}\n",
    "\n",
    "prompt = \"\"\"The intrinsic matrix for Image 1 is given as:\n",
    "\n",
    "[[1.24885779e+03 0.00000000e+00 5.16500000e+02]\n",
    " [0.00000000e+00 1.24885779e+03 3.42500000e+02]\n",
    " [0.00000000e+00 0.00000000e+00 1.00000000e+00]]\n",
    "\n",
    "Image 2 is captured under similar conditions to Image 1, though there may be slight differences in the camera position or lens orientation. The focal length of Image 2 is likely in the range of 700 to 900, but it may differ slightly from Image 1. The scene and lighting are similar, but there might be small variations in the image, especially considering the slight difference in camera position. Based on these factors, predict the intrinsic matrix for Image 2 that best reflects the small variations between the two images.\n",
    "\n",
    "Intrinsic Matrix (Image 2):\n",
    "[[f_x, 0, c_x], [0, f_y, c_y], [0, 0, 1]]\n",
    "the values for f_x and f_y differ slightly from Image 1 based on the image features and matches. Do not include additional explanations.\"\"\"\n",
    "\n",
    "response = model.generate_content([sample_file_1, sample_file_2, prompt])\n",
    "\n",
    "Markdown(response.text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
